#!/usr/bin/env python3
"""
éªŒè¯æ ¡å‡†æ•ˆæœ - å¯¹æ¯”V3åŸå§‹ vs V3æ ¡å‡†ç‰ˆçš„å‡†ç¡®ç‡å’ŒROI
"""
import pandas as pd
import pickle
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent
MODELS_DIR = PROJECT_ROOT / 'models'
DATA_DIR = PROJECT_ROOT / 'data'

def load_model():
    """åŠ è½½V3æ¨¡å‹"""
    filepath = MODELS_DIR / 'total_points_model_v3.pkl'
    with open(filepath, 'rb') as f:
        return pickle.load(f)

def load_features():
    """åŠ è½½ç‰¹å¾æ•°æ®"""
    filepath = DATA_DIR / 'features' / 'features_v3.csv'
    return pd.read_csv(filepath)

def evaluate_predictions(df, calibration=0):
    """è¯„ä¼°é¢„æµ‹å‡†ç¡®ç‡å’ŒROI"""
    # Line 215å‡†ç¡®ç‡
    correct_215 = sum((df['total_points'] > 215) == (df['predicted'] > 215))
    accuracy_215 = correct_215 / len(df) * 100
    
    # Line 220
    correct_220 = sum((df['total_points'] > 220) == (df['predicted'] > 220))
    accuracy_220 = correct_220 / len(df) * 100
    
    # Line 225
    correct_225 = sum((df['total_points'] > 225) == (df['predicted'] > 225))
    accuracy_225 = correct_225 / len(df) * 100
    
    # é«˜ä¿¡å¿ƒä¸‹æ³¨æ¨¡æ‹Ÿï¼ˆ>5%ï¼‰
    df['confidence'] = abs(df['predicted'] - 215) / 215 * 100
    high_conf = df[df['confidence'] > 5].copy()
    
    if len(high_conf) > 0:
        correct_hc = sum((high_conf['total_points'] > 215) == (high_conf['predicted'] > 215))
        accuracy_hc = correct_hc / len(high_conf) * 100
        roi_hc = (correct_hc - len(high_conf)) / len(high_conf) * 95  # -5% vig
    else:
        accuracy_hc = 0
        roi_hc = 0
    
    # MAE
    mae = df['error'].abs().mean()
    
    return {
        'accuracy_215': accuracy_215,
        'accuracy_220': accuracy_220,
        'accuracy_225': accuracy_225,
        'high_conf_games': len(high_conf),
        'high_conf_accuracy': accuracy_hc,
        'roi': roi_hc,
        'mae': mae,
        'avg_error': df['error'].mean()  # å¹³å‡åå·®ï¼ˆæ­£=é«˜ä¼°ï¼Œè´Ÿ=ä½ä¼°ï¼‰
    }

def main():
    print("\n" + "="*70)
    print("ğŸ“Š éªŒè¯æ ¡å‡†æ•ˆæœ: V3åŸå§‹ vs V3æ ¡å‡†(+2.7)")
    print("="*70 + "\n")
    
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    model_pkg = load_model()
    features_df = load_features()
    
    # åˆ é™¤ç¼ºå¤±å€¼
    features_df = features_df.dropna(subset=['combined_pts_last_3', 'combined_pts_last_5'])
    
    # å‡†å¤‡ç‰¹å¾
    feature_cols = model_pkg['feature_cols']
    X = features_df[feature_cols].fillna(0)
    y_true = features_df['total_points']
    
    # åŸå§‹é¢„æµ‹
    y_pred_raw = model_pkg['model'].predict(X)
    
    # æ ¡å‡†é¢„æµ‹
    y_pred_calibrated = y_pred_raw + 2.7
    
    # è¯„ä¼°åŸå§‹ç‰ˆ
    df_raw = pd.DataFrame({
        'total_points': y_true,
        'predicted': y_pred_raw,
        'error': y_true - y_pred_raw
    })
    results_raw = evaluate_predictions(df_raw)
    
    # è¯„ä¼°æ ¡å‡†ç‰ˆ
    df_cal = pd.DataFrame({
        'total_points': y_true,
        'predicted': y_pred_calibrated,
        'error': y_true - y_pred_calibrated
    })
    results_cal = evaluate_predictions(df_cal, calibration=2.7)
    
    # å¯¹æ¯”è¡¨æ ¼
    print(f"{'æŒ‡æ ‡':<25s} {'V3åŸå§‹':<15s} {'V3æ ¡å‡†(+2.7)':<15s} {'æ”¹è¿›':<10s}")
    print("-" * 70)
    
    metrics = [
        ('MAE (å¹³å‡ç»å¯¹è¯¯å·®)', 'mae', 'åˆ†'),
        ('å¹³å‡åå·® (ç³»ç»Ÿè¯¯å·®)', 'avg_error', 'åˆ†'),
        ('Line 215å‡†ç¡®ç‡', 'accuracy_215', '%'),
        ('Line 220å‡†ç¡®ç‡', 'accuracy_220', '%'),
        ('Line 225å‡†ç¡®ç‡', 'accuracy_225', '%'),
        ('é«˜ä¿¡å¿ƒæ¯”èµ›æ•°', 'high_conf_games', 'åœº'),
        ('é«˜ä¿¡å¿ƒå‡†ç¡®ç‡', 'high_conf_accuracy', '%'),
        ('ç†è®ºROI', 'roi', '%')
    ]
    
    for label, key, unit in metrics:
        raw_val = results_raw[key]
        cal_val = results_cal[key]
        diff = cal_val - raw_val
        
        if unit == 'åˆ†':
            raw_str = f"{raw_val:.2f}{unit}"
            cal_str = f"{cal_val:.2f}{unit}"
            diff_str = f"{diff:+.2f}{unit}"
        elif unit == '%':
            raw_str = f"{raw_val:.1f}{unit}"
            cal_str = f"{cal_val:.1f}{unit}"
            diff_str = f"{diff:+.1f}{unit}"
        else:
            raw_str = f"{int(raw_val)}{unit}"
            cal_str = f"{int(cal_val)}{unit}"
            diff_str = f"{int(diff):+d}{unit}"
        
        print(f"{label:<25s} {raw_str:<15s} {cal_str:<15s} {diff_str:<10s}")
    
    print("\n" + "="*70)
    print("ğŸ’¡ ç»“è®º:")
    print("-" * 70)
    
    if results_cal['mae'] < results_raw['mae']:
        print(f"âœ… æ ¡å‡†åMAEæ”¹å–„ {results_raw['mae'] - results_cal['mae']:.2f}åˆ†")
    else:
        print(f"âŒ æ ¡å‡†åMAEæ¶åŒ– {results_cal['mae'] - results_raw['mae']:.2f}åˆ†")
    
    if abs(results_cal['avg_error']) < abs(results_raw['avg_error']):
        print(f"âœ… ç³»ç»Ÿåå·®ä»{results_raw['avg_error']:.2f}åˆ†é™ä½åˆ°{results_cal['avg_error']:.2f}åˆ†")
    else:
        print(f"âš ï¸  ç³»ç»Ÿåå·®ä»{results_raw['avg_error']:.2f}åˆ†å˜ä¸º{results_cal['avg_error']:.2f}åˆ†")
    
    if results_cal['accuracy_215'] > results_raw['accuracy_215']:
        print(f"âœ… Line 215å‡†ç¡®ç‡æå‡ {results_cal['accuracy_215'] - results_raw['accuracy_215']:.1f}%")
    else:
        print(f"âš ï¸  Line 215å‡†ç¡®ç‡ä¸‹é™ {results_cal['accuracy_215'] - results_raw['accuracy_215']:.1f}%")
    
    if results_cal['roi'] > results_raw['roi']:
        print(f"âœ… ç†è®ºROIæå‡ {results_cal['roi'] - results_raw['roi']:.1f}%")
    else:
        print(f"âš ï¸  ç†è®ºROIä¸‹é™ {results_cal['roi'] - results_raw['roi']:.1f}%")
    
    print("\n" + "="*70 + "\n")

if __name__ == '__main__':
    main()
